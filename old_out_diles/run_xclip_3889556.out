nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2023 NVIDIA Corporation
Built on Mon_Apr__3_17:16:06_PDT_2023
Cuda compilation tools, release 12.1, V12.1.105
Build cuda_12.1.r12.1/compiler.32688072_0
g++ (GCC) 12.3.0
Copyright (C) 2022 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

## Available CUDA devices: 0,1
## Checking status of CUDA device with nvidia-smi
Thu Mar 20 18:16:38 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:62:00.0 Off |                  N/A |
| 29%   30C    P8              5W /  250W |       1MiB /  11264MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:C1:00.0 Off |                  N/A |
| 29%   28C    P8             22W /  250W |       1MiB /  11264MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
[nltk_data] Downloading package wordnet to /home/s3705609/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
usage: main_xclip.py [-h] [--do_pretrain] [--do_train] [--do_eval]
                     [--train_csv TRAIN_CSV] [--val_csv VAL_CSV]
                     [--data_path DATA_PATH] [--features_path FEATURES_PATH]
                     [--num_thread_reader NUM_THREAD_READER] [--lr LR]
                     [--epochs EPOCHS] [--batch_size BATCH_SIZE]
                     [--batch_size_val BATCH_SIZE_VAL] [--lr_decay LR_DECAY]
                     [--n_display N_DISPLAY] [--video_dim VIDEO_DIM]
                     [--seed SEED] [--max_words MAX_WORDS]
                     [--max_frames MAX_FRAMES]
                     [--feature_framerate FEATURE_FRAMERATE] [--margin MARGIN]
                     [--hard_negative_rate HARD_NEGATIVE_RATE]
                     [--negative_weighting NEGATIVE_WEIGHTING]
                     [--n_pair N_PAIR] --output_dir OUTPUT_DIR
                     [--cross_model CROSS_MODEL] [--init_model INIT_MODEL]
                     [--resume_model RESUME_MODEL] [--do_lower_case]
                     [--warmup_proportion WARMUP_PROPORTION]
                     [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                     [--n_gpu N_GPU] [--cache_dir CACHE_DIR] [--fp16]
                     [--fp16_opt_level FP16_OPT_LEVEL] [--task_type TASK_TYPE]
                     [--datatype DATATYPE] [--world_size WORLD_SIZE]
                     [--local_rank LOCAL_RANK] [--rank RANK]
                     [--coef_lr COEF_LR] [--use_mil] [--sampled_use_mil]
                     [--text_num_hidden_layers TEXT_NUM_HIDDEN_LAYERS]
                     [--visual_num_hidden_layers VISUAL_NUM_HIDDEN_LAYERS]
                     [--cross_num_hidden_layers CROSS_NUM_HIDDEN_LAYERS]
                     [--loose_type] [--expand_msrvtt_sentences]
                     [--train_frame_order {0,1,2}]
                     [--eval_frame_order {0,1,2}]
                     [--freeze_layer_num FREEZE_LAYER_NUM]
                     [--slice_framepos {0,1,2}] [--linear_patch {2d,3d}]
                     [--sim_header {meanP,seqLSTM,seqTransf,tightTransf}]
                     [--pretrained_clip_name PRETRAINED_CLIP_NAME]
main_xclip.py: error: unrecognized arguments:  
[2025-03-20 18:16:56,191] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 3208486) of binary: /data1/s3705609/venv_clip/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/easybuild/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/distributed/run.py", line 810, in <module>
    main()
  File "/easybuild/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/easybuild/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/easybuild/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/easybuild/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/easybuild/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_xclip.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-03-20_18:16:56
  host      : node854.cm.cluster
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 3208486)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/s3705609/X-CLIP/scripts/run_xclip_vatex_vit16.sh: line 12: --feature_framerate: command not found
