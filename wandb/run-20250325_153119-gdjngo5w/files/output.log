03/25/2025 15:31:21 - INFO -   Weights & Biases logging enabled
03/25/2025 15:31:21 - INFO -   Weights & Biases logging initialized
Model path: /home/s3705609/X-CLIP/modules/ViT-B-32.pt
Model path 2: /home/s3705609/.cache/clip/ViT-B-32.pt
Loaded JIT model
03/25/2025 15:31:23 - INFO -   loading archive file /home/s3705609/X-CLIP/modules/cross-base
03/25/2025 15:31:23 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

03/25/2025 15:31:23 - INFO -   Weight doesn't exsits. /home/s3705609/X-CLIP/modules/cross-base/cross_pytorch_model.bin
03/25/2025 15:31:23 - WARNING -   Stage-One:True, Stage-Two:False
03/25/2025 15:31:23 - WARNING -   Test retrieval by loose type.
03/25/2025 15:31:23 - WARNING -   	 embed_dim: 512
03/25/2025 15:31:23 - WARNING -   	 image_resolution: 224
03/25/2025 15:31:23 - WARNING -   	 vision_layers: 12
03/25/2025 15:31:23 - WARNING -   	 vision_width: 768
03/25/2025 15:31:23 - WARNING -   	 vision_patch_size: 32
03/25/2025 15:31:23 - WARNING -   	 context_length: 77
03/25/2025 15:31:23 - WARNING -   	 vocab_size: 49408
03/25/2025 15:31:23 - WARNING -   	 transformer_width: 512
03/25/2025 15:31:23 - WARNING -   	 transformer_heads: 8
03/25/2025 15:31:23 - WARNING -   	 transformer_layers: 12
03/25/2025 15:31:23 - WARNING -   		 linear_patch: 2d
03/25/2025 15:31:23 - WARNING -   	 cut_top_layer: 0
03/25/2025 15:31:26 - WARNING -   	 sim_header: seqTransf
03/25/2025 15:31:37 - INFO -   --------------------
03/25/2025 15:31:37 - INFO -   Weights of XCLIP not initialized from pretrained model:
   global_mat_weight
   word_logit_weight
   frame_logit_weight
   local_mat_weight
   frame_mat_weight
   word_mat_weight
   frame_mat_weight2
   word_mat_weight2
03/25/2025 15:31:37 - INFO -   Weights from pretrained model not used in XCLIP:
   clip.input_resolution
   clip.context_length
   clip.vocab_size
03/25/2025 15:31:37 - INFO -   Model has 260,258,738 trainable parameters and 27,736,320 frozen parameters
03/25/2025 15:31:46 - INFO -   ***** Running test *****
03/25/2025 15:31:46 - INFO -     Num examples = 33910
03/25/2025 15:31:46 - INFO -     Batch size = 16
03/25/2025 15:31:46 - INFO -     Num steps = 2120
03/25/2025 15:31:46 - INFO -   ***** Running val *****
03/25/2025 15:31:46 - INFO -     Num examples = 23750
Total Paire: train 237770
Video number: 23777
Total Paire: train 237770
03/25/2025 15:32:03 - INFO -   ***** Running training *****
03/25/2025 15:32:03 - INFO -     Num examples = 237770
03/25/2025 15:32:03 - INFO -     Batch size = 16
03/25/2025 15:32:03 - INFO -     Num steps = 74300
03/25/2025 15:35:59 - INFO -   Epoch: 1/5, Step: 100/14860, Lr: 0.000000100-0.000100000, Loss: 0.187226, Time/step: 2.361481
03/25/2025 15:39:36 - INFO -   Epoch: 1/5, Step: 200/14860, Lr: 0.000000100-0.000100000, Loss: 0.397710, Time/step: 2.163514
03/25/2025 15:43:15 - INFO -   Epoch: 1/5, Step: 300/14860, Lr: 0.000000100-0.000100000, Loss: 0.494316, Time/step: 2.192659
03/25/2025 15:46:49 - INFO -   Epoch: 1/5, Step: 400/14860, Lr: 0.000000100-0.000100000, Loss: 0.371775, Time/step: 2.136326
03/25/2025 15:50:31 - INFO -   Epoch: 1/5, Step: 500/14860, Lr: 0.000000100-0.000100000, Loss: 0.203949, Time/step: 2.219867
03/25/2025 15:54:00 - INFO -   Epoch: 1/5, Step: 600/14860, Lr: 0.000000100-0.000100000, Loss: 0.445359, Time/step: 2.093556
03/25/2025 15:57:43 - INFO -   Epoch: 1/5, Step: 700/14860, Lr: 0.000000100-0.000100000, Loss: 0.095403, Time/step: 2.233857
03/25/2025 16:01:09 - INFO -   Epoch: 1/5, Step: 800/14860, Lr: 0.000000100-0.000100000, Loss: 0.124595, Time/step: 2.053488
03/25/2025 16:04:53 - INFO -   Epoch: 1/5, Step: 900/14860, Lr: 0.000000100-0.000100000, Loss: 0.070438, Time/step: 2.239228
03/25/2025 16:08:23 - INFO -   Epoch: 1/5, Step: 1000/14860, Lr: 0.000000100-0.000100000, Loss: 0.058984, Time/step: 2.104468
03/25/2025 16:12:05 - INFO -   Epoch: 1/5, Step: 1100/14860, Lr: 0.000000100-0.000100000, Loss: 0.172794, Time/step: 2.218938
03/25/2025 16:15:35 - INFO -   Epoch: 1/5, Step: 1200/14860, Lr: 0.000000100-0.000100000, Loss: 0.128213, Time/step: 2.095389
03/25/2025 16:19:14 - INFO -   Epoch: 1/5, Step: 1300/14860, Lr: 0.000000100-0.000100000, Loss: 0.021835, Time/step: 2.196157
03/25/2025 16:22:45 - INFO -   Epoch: 1/5, Step: 1400/14860, Lr: 0.000000100-0.000100000, Loss: 0.237784, Time/step: 2.111798
03/25/2025 16:26:24 - INFO -   Epoch: 1/5, Step: 1500/14860, Lr: 0.000000100-0.000100000, Loss: 0.033244, Time/step: 2.189595
03/25/2025 16:29:50 - INFO -   Epoch: 1/5, Step: 1600/14860, Lr: 0.000000100-0.000100000, Loss: 0.022929, Time/step: 2.056660
03/25/2025 16:33:28 - INFO -   Epoch: 1/5, Step: 1700/14860, Lr: 0.000000100-0.000100000, Loss: 0.075279, Time/step: 2.176435
03/25/2025 16:36:50 - INFO -   Epoch: 1/5, Step: 1800/14860, Lr: 0.000000100-0.000100000, Loss: 0.053636, Time/step: 2.021785
03/25/2025 16:40:28 - INFO -   Epoch: 1/5, Step: 1900/14860, Lr: 0.000000100-0.000100000, Loss: 0.138435, Time/step: 2.180515
